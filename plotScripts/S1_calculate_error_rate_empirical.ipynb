{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import scipy.spatial.distance as sci_dist\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# Configure matplotlib and numpy settings\n",
    "matplotlib.use('QtAgg')\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "np.random.seed(0)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "tools_path = '../helperScripts/tools.py'\n",
    "sys.path.append(os.path.dirname(os.path.expanduser(tools_path)))\n",
    "import tools as tools\n",
    "\n",
    "# Define file paths\n",
    "data_folder = tools.roi_file_paths['dish_roi2']['out_path']\n",
    "# data_folder = '/Users/yaelheyman/RajLab Dropbox/Yael Heyman/SpatialBarcodes/ImagingData/2024-02-27_spatialbarcodes_SG_expression/projects/2024-02-27_spatialbarcodes_expression/roi_2/exports'\n",
    "region_data_path = '../extractedData/in_vitro/Region_Data_with_Minimal_Values.csv'\n",
    "# region_data_path = '/Users/YaelHeyman/RajLab Dropbox/Yael Heyman/SpatialBarcodes/ImagingData/2024-02-27_spatialbarcodes_SG_expression/processedData/Region_Data_with_Minimal_Values.csv'\n",
    "cell_by_gene_path = os.path.join(data_folder, 'cell_by_gene_matrix_dilate10_20240718_withbarcodes_clustering_10bcs_0.2thresh.csv')\n",
    "data_output_folder = '../extractedData/in_vitro'\n",
    "plot_output_folder = '../graphs'\n",
    "\n",
    "def calculate_polygon_area(vertices):\n",
    "    \"\"\"Calculate the area of a polygon given its vertices as a NumPy array.\n",
    "    \n",
    "    Arguments:\n",
    "    vertices -- a NumPy array of shape (N, 2), where N is the number of vertices\n",
    "    \n",
    "    Returns:\n",
    "    The area of the polygon.\n",
    "    \"\"\"\n",
    "    # Ensure the first vertex is also the last (to close the polygon)\n",
    "    if not np.array_equal(vertices[0], vertices[-1]):\n",
    "        vertices = np.vstack([vertices, vertices[0]])\n",
    "    \n",
    "    # Calculate the sum of the cross-products\n",
    "    x0 = vertices[:-1, 0]\n",
    "    y1 = vertices[1:, 1]\n",
    "    y0 = vertices[:-1, 1]\n",
    "    x1 = vertices[1:, 0]\n",
    "    \n",
    "    # Calculate the area using the shoelace formula\n",
    "    area = abs(np.sum(x0 * y1) - np.sum(y0 * x1)) / 2.0\n",
    "    return area\n",
    "\n",
    "def max_dist(coords, ids):\n",
    "    \"\"\"Calculate maximum distance between points and enclosed area.\n",
    "    \n",
    "    Arguments:\n",
    "    coords -- coordinate array\n",
    "    ids -- indices of points to consider\n",
    "    \n",
    "    Returns:\n",
    "    max_val -- maximum distance between any two points\n",
    "    area_enclosed -- area of polygon formed by points\n",
    "    \"\"\"\n",
    "    distance = sci_dist.pdist(coords[ids,:])\n",
    "    dist_mat = sci_dist.squareform(distance)\n",
    "    max_val = np.max(dist_mat)\n",
    "    area_enclosed = calculate_polygon_area(coords[ids,:])\n",
    "    return max_val, area_enclosed\n",
    "\n",
    "# Load and process region data\n",
    "region_data = pd.read_csv(region_data_path)\n",
    "pixel2mm = 107.11 / 1000000  # Convert pixel to milimeters\n",
    "\n",
    "# Combine data from multiple regions\n",
    "combined_df = pd.DataFrame()\n",
    "for j in range(1, 4):  # Process regions 1-3\n",
    "    data_folder = f\"/Users/yaelheyman/RajLab Dropbox/Yael Heyman/SpatialBarcodes/ImagingData/2024-02-27_spatialbarcodes_SG_expression/projects/2024-02-27_spatialbarcodes_expression/roi_{j}/exports\"\n",
    "    cell_by_gene_path = os.path.join(data_folder, 'cell_by_gene_matrix_dilate10_20240718_withbarcodes_clustering_10bcs_0.2thresh.csv')\n",
    "    \n",
    "    # Load cell by gene data\n",
    "    cell_by_gene = pd.read_csv(cell_by_gene_path, index_col=0)\n",
    "    \n",
    "    # Get reference coordinates\n",
    "    ref_x = region_data.loc[region_data['Region'] == f\"Region {j}\", \"Min X (mm)\"].iloc[0]\n",
    "    ref_y = region_data.loc[region_data['Region'] == f\"Region {j}\", \"Min Y (mm)\"].iloc[0]\n",
    "    \n",
    "    # Correct coordinates\n",
    "    cell_by_gene['center_x'] = (cell_by_gene['center_x'] * pixel2mm + ref_x) * 1000\n",
    "    cell_by_gene['center_y'] = (cell_by_gene['center_y'] * pixel2mm + ref_y) * 1000\n",
    "    \n",
    "    # Make cell IDs unique across regions\n",
    "    cell_by_gene['cell_id'] = cell_by_gene['cell_id'] + j * 100000\n",
    "    \n",
    "    # Append to combined dataset\n",
    "    combined_df = pd.concat([combined_df, cell_by_gene], ignore_index=True)\n",
    "\n",
    "# Save combined dataset\n",
    "combined_df.to_csv(os.path.join(output_folder, 'combined_df.csv'))\n",
    "\n",
    "# Process barcode data\n",
    "cell_by_gene = combined_df.copy()\n",
    "coords = cell_by_gene[['center_x', 'center_y']].to_numpy()\n",
    "\n",
    "# Create dictionary of barcode indices\n",
    "barcode_indices = {}\n",
    "for index, barcode in enumerate(cell_by_gene['barcode_names']):\n",
    "    barcode_key = barcode if barcode == barcode else 'NaN'\n",
    "    barcode_indices.setdefault(barcode_key, []).append(index)\n",
    "\n",
    "# Calculate distances and areas for sister cells\n",
    "indices_list = list(barcode_indices.values())\n",
    "cell_by_gene['sisters_max_distance'] = pd.NA\n",
    "cell_by_gene['sisters_enclosed_area'] = pd.NA\n",
    "\n",
    "for ids in indices_list:\n",
    "    max_dist_val, area_enclosed = max_dist(coords, ids)\n",
    "    for row_index in ids:\n",
    "        cell_by_gene.iloc[row_index, cell_by_gene.columns.get_loc('sisters_max_distance')] = max_dist_val\n",
    "        cell_by_gene.iloc[row_index, cell_by_gene.columns.get_loc('sisters_enclosed_area')] = area_enclosed\n",
    "\n",
    "# Filter cells that do not have barcodes or have over 12 barcodes and analyze data\n",
    "filtered_df = cell_by_gene[(cell_by_gene['n_called_barcodes'] > 0) & (cell_by_gene['n_called_barcodes'] <= 12)]\n",
    "\n",
    "# Initialize arrays for statistics\n",
    "max_distance_sisters = np.array([])\n",
    "mean_distance_sisters = np.array([])\n",
    "median_distance_sisters = np.array([])\n",
    "percentile99_distance_sisters = np.array([])\n",
    "exception = np.array([])\n",
    "\n",
    "# Calculate statistics for each number of barcodes\n",
    "for num_barcodes in np.unique(filtered_df[\"n_called_barcodes\"]):\n",
    "    idx = (filtered_df[\"n_called_barcodes\"] == num_barcodes) & (filtered_df[\"sisters_max_distance\"] > 0)\n",
    "    if filtered_df.loc[idx][\"sisters_max_distance\"].empty:\n",
    "        exception = np.append(exception, num_barcodes)\n",
    "        continue\n",
    "        \n",
    "    sister_distances = filtered_df.loc[idx][\"sisters_max_distance\"]\n",
    "    max_distance_sisters = np.append(max_distance_sisters, np.max(sister_distances))\n",
    "    mean_distance_sisters = np.append(mean_distance_sisters, np.mean(sister_distances))\n",
    "    median_distance_sisters = np.append(median_distance_sisters, np.median(sister_distances))\n",
    "    percentile99_distance_sisters = np.append(percentile99_distance_sisters, \n",
    "                                            np.percentile(sister_distances, 99))\n",
    "\n",
    "# Plot distance statistics\n",
    "# Convert 6 cm to inches\n",
    "width_in = 7 / 2.54\n",
    "height_in = 7 / 2.54\n",
    "\n",
    "# Create figure of size 6 cm by 6 cm\n",
    "fig, ax = plt.subplots(figsize=(width_in, height_in))\n",
    "\n",
    "x = np.setdiff1d(np.unique(filtered_df[\"n_called_barcodes\"]), exception)\n",
    "\n",
    "# Plotting the 99th percentile distance\n",
    "f4, = plt.plot(x, percentile99_distance_sisters, label='99th percentile')\n",
    "\n",
    "# Find the y-value corresponding to x = 4\n",
    "if 4 in x:\n",
    "    y_value = percentile99_distance_sisters[np.where(x == 4)][0]\n",
    "    plt.axhline(y=y_value, color='red', linestyle='--', label=f'clone distance = {y_value:.1f} um')\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=6)\n",
    "\n",
    "# Create legend with 8-pt text\n",
    "ax.legend(fontsize=8,loc='upper right')\n",
    "\n",
    "# Optional: Set axis labels if needed\n",
    "ax.set_xlabel(\"number of barcodes per cell\", fontsize=8)\n",
    "ax.set_ylabel(\"distance between sister cells (um)\", fontsize=8)\n",
    "special_tick = y_value\n",
    "\n",
    "# 1. Get the current y-ticks\n",
    "current_yticks = list(ax.get_yticks())\n",
    "\n",
    "# 2. Add the new tick, then sort the list\n",
    "current_yticks.append(special_tick)\n",
    "current_yticks.sort()\n",
    "\n",
    "# 3. Update the axis ticks\n",
    "ax.set_yticks(current_yticks)\n",
    "\n",
    "# Create string labels for each tick\n",
    "labels_str = [f'{val:.0f}' for val in current_yticks]\n",
    "\n",
    "# 4. Apply these labels and color the special one red\n",
    "label_objects = ax.set_yticklabels(labels_str)\n",
    "special_index = current_yticks.index(special_tick)\n",
    "label_objects[special_index].set_color('red')\n",
    "# Tight layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(os.path.join(plot_output_folder, 'num_bc_vs_sisterhood_dist.pdf'),bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(8269.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(combined_df['bc_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot error rates\n",
    "thresh_dist = y_value #above this distance the sisterhood would be considered to have an error\n",
    "error_rate_num_bc = np.array([])\n",
    "\n",
    "for num_barcodes in np.unique(filtered_df[\"n_called_barcodes\"]):\n",
    "    idx = (filtered_df[\"n_called_barcodes\"] == num_barcodes) & (filtered_df[\"sisters_max_distance\"] > 0)\n",
    "    if filtered_df.loc[idx][\"sisters_max_distance\"].empty:\n",
    "        continue\n",
    "    \n",
    "    error_rate = np.sum(filtered_df.loc[idx][\"sisters_max_distance\"] > thresh_dist)/len(filtered_df.loc[idx][\"sisters_max_distance\"])\n",
    "    error_rate_num_bc = np.append(error_rate_num_bc, error_rate)\n",
    "\n",
    "# Plot error rates\n",
    "plt.figure()\n",
    "x = np.setdiff1d(np.unique(filtered_df[\"n_called_barcodes\"]), exception)\n",
    "plt.plot(x, error_rate_num_bc, label='error rate')\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.ylabel('error rate (frequency of clones with above threshold size)')\n",
    "plt.xlabel('number of barcodes per cell')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_barcodes  error_rate\n",
      "0             1    0.988390\n",
      "1             2    0.627887\n",
      "2             3    0.060467\n",
      "3             4    0.003386\n",
      "4             5    0.000242\n",
      "5             6    0.000000\n",
      "6             7    0.000000\n",
      "7             8    0.000000\n",
      "8             9    0.000000\n",
      "9            10    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate cumulative error rates and theoretical error rates\n",
    "error_rate_num_bc = np.array([])\n",
    "percentage_more_than = np.array([])\n",
    "\n",
    "for num_barcodes in np.unique(filtered_df[\"n_called_barcodes\"]):\n",
    "    idx = (filtered_df[\"n_called_barcodes\"] ==num_barcodes) & (filtered_df[\"sisters_max_distance\"] > 0)\n",
    "    \n",
    "    if filtered_df.loc[idx][\"sisters_max_distance\"].empty:\n",
    "        exception = np.append(exception, num_barcodes)\n",
    "        continue\n",
    "    \n",
    "    # Calculate empirical error rate\n",
    "    error_rate = np.sum(filtered_df.loc[idx][\"sisters_max_distance\"] > thresh_dist) / len(filtered_df.loc[idx][\"sisters_max_distance\"])\n",
    "    error_rate_num_bc = np.append(error_rate_num_bc, error_rate)\n",
    "    \n",
    "    # Calculate percentage of cells with more than current number of barcodes\n",
    "    percentage = np.sum(idx) / len(filtered_df[\"n_called_barcodes\"] >= 0)\n",
    "    percentage_more_than = np.append(percentage_more_than, percentage)\n",
    "\n",
    "# Calculate theoretical error rates\n",
    "n = len(combined_df[\"barcode_names\"].unique())\n",
    "bc_lib_size = 96\n",
    "error_rates = []\n",
    "\n",
    "\n",
    "\n",
    "def compute_error_rate(barcodes, probabilities, num_initial_cells, sample_size=3):\n",
    "    \"\"\"\n",
    "    Simulate sampling without replacement and compute error rate.\n",
    "    Error rate = fraction of samples that are duplicates (unordered).\n",
    "    \"\"\"\n",
    "    samples = [\n",
    "        tuple(sorted(np.random.choice(barcodes, size=sample_size, replace=False, p=probabilities)))\n",
    "        for _ in range(num_initial_cells)\n",
    "    ]\n",
    "    unique_samples = set(samples)\n",
    "    n_duplicates = len(samples) - len(unique_samples)\n",
    "    error_rate = n_duplicates / len(samples)\n",
    "    return error_rate\n",
    "\n",
    "# Generate barcode pool and abundance distribution\n",
    "barcodes = np.array([f'bc_{i:03d}' for i in range(1, bc_lib_size+1)])  # 96 barcodes\n",
    "barcode_df = pd.read_csv(os.path.join(data_folder, 'barcode_probabilities.csv'))\n",
    "barcodes = barcode_df['barcode'].to_numpy()\n",
    "probabilities = barcode_df['probability'].to_numpy()\n",
    "\n",
    "# Iterate over sample sizes 1 through 11\n",
    "results = []\n",
    "for size in range(1, 11):\n",
    "    error = compute_error_rate(barcodes, probabilities, num_initial_cells = int(np.max(combined_df['bc_cluster'])),sample_size=size)\n",
    "    results.append((size, error))\n",
    "\n",
    "# Create a results DataFrame\n",
    "df_error_rates = pd.DataFrame(results, columns=[\"num_barcodes\", \"error_rate\"])\n",
    "print(df_error_rates)\n",
    "\n",
    "\n",
    "# Plot empirical vs theoretical error rates\n",
    "width_in = 7 / 2.54\n",
    "height_in = 7 / 2.54\n",
    "\n",
    "# Create figure of size 6 cm by 6 cm\n",
    "fig, ax = plt.subplots(figsize=(width_in, height_in))\n",
    "plt.subplots_adjust(left=0.05, bottom=0.05, right=0.9, top=0.98)\n",
    "\n",
    "x = np.setdiff1d(np.unique(filtered_df[\"n_called_barcodes\"]), exception)\n",
    "f1, = plt.plot(x, error_rate_num_bc, label='Empirical Error Rate')\n",
    "f2, = plt.plot(range(1, 11), df_error_rates['error_rate'].values, 'r', label='Theoretical Error Rate')\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=6)\n",
    "\n",
    "# Create legend with 8-pt text\n",
    "ax.legend(fontsize=8,loc='upper right')\n",
    "\n",
    "plt.ylabel('frequency of clones with above threshold', fontsize=8)\n",
    "plt.xlabel('number of barcodes per cell',fontsize=8)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(output_folder, 'expected vs measured error rate.pdf'),bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number of initial cells  error rate using 3 barcodes  \\\n",
      "0                     1000                       0.0120   \n",
      "1                    10000                       0.0705   \n",
      "2                   100000                       0.4330   \n",
      "\n",
      "   error rate using 4 barcodes  \n",
      "0                       0.0010  \n",
      "1                       0.0047  \n",
      "2                       0.0426  \n"
     ]
    }
   ],
   "source": [
    "# Define different numbers of cells to simulate\n",
    "cell_counts = [1000, 10000, 100000]\n",
    "\n",
    "# Prepare results\n",
    "multi_size_results = []\n",
    "\n",
    "for n_cells in cell_counts:\n",
    "    err_3 = compute_error_rate(barcodes, probabilities, num_initial_cells=n_cells, sample_size=3)\n",
    "    err_4 = compute_error_rate(barcodes, probabilities, num_initial_cells=n_cells, sample_size=4)\n",
    "    multi_size_results.append((n_cells, err_3, err_4))\n",
    "\n",
    "# Create DataFrame\n",
    "df_multi_size = pd.DataFrame(multi_size_results, columns=[\"number of initial cells\", \"error rate using 3 barcodes\", \"error rate using 4 barcodes\"])\n",
    "print(df_multi_size)\n",
    "\n",
    "# Optional: Save to CSV\n",
    "df_multi_size.to_csv(os.path.join(data_output_folder, 'error_rate_by_cell_number.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Format values\n",
    "df_rounded = df_multi_size.copy()\n",
    "\n",
    "# Format cell counts as integers (no decimal)\n",
    "df_rounded[\"number of initial cells\"] = df_rounded[\"number of initial cells\"].astype(int)\n",
    "\n",
    "# Convert error rates to percentages\n",
    "df_rounded[\"error rate using 3 barcodes\"] = (df_rounded[\"error rate using 3 barcodes\"] * 100).round(1).astype(str) + \"%\"\n",
    "df_rounded[\"error rate using 4 barcodes\"] = (df_rounded[\"error rate using 4 barcodes\"] * 100).round(1).astype(str) + \"%\"\n",
    "\n",
    "# Rename columns with line breaks for better wrapping\n",
    "df_rounded.columns = [\n",
    "    \"Number of\\ninitial cells\",\n",
    "    \"Error rate\\n(3 barcodes)\",\n",
    "    \"Error rate\\n(4 barcodes)\"\n",
    "]\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(4.5, 1.6))\n",
    "ax.axis('off')\n",
    "\n",
    "# Create table\n",
    "table = ax.table(\n",
    "    cellText=df_rounded.values,\n",
    "    colLabels=df_rounded.columns,\n",
    "    loc='center',\n",
    "    cellLoc='center',\n",
    "    colLoc='center',\n",
    "    bbox=[0, 0, 1, 1]\n",
    ")\n",
    "\n",
    "# Styling\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(8)\n",
    "table.scale(1.2, 1.4)\n",
    "\n",
    "# Fit column widths to headers\n",
    "for i in range(len(df_rounded.columns)):\n",
    "    table.auto_set_column_width(i)\n",
    "\n",
    "# Save\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(data_output_folder, \"error_rate_table_percentage.pdf\"), bbox_inches=\"tight\")\n",
    "plt.savefig(os.path.join(data_output_folder, \"error_rate_table_percentage.svg\"), bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.setdiff1d(np.unique(filtered_df[\"n_called_barcodes\"]), exception)\n",
    "error_rate_num_bc = np.array([])\n",
    "percentage_more_than = np.array([])\n",
    "for num_barcodes in np.unique(filtered_df[\"n_called_barcodes\"]):\n",
    "    idx = (filtered_df[\"n_called_barcodes\"] >= num_barcodes) & (filtered_df[\"sisters_max_distance\"] > 0)\n",
    "    \n",
    "    if filtered_df.loc[idx][\"sisters_max_distance\"].empty:\n",
    "        exception = np.append(exception, num_barcodes)\n",
    "        continue\n",
    "    \n",
    "    # Calculate empirical error rate\n",
    "    error_rate = np.sum(filtered_df.loc[idx][\"sisters_max_distance\"] > thresh_dist) / len(filtered_df.loc[idx][\"sisters_max_distance\"])\n",
    "    error_rate_num_bc = np.append(error_rate_num_bc, error_rate)\n",
    "    \n",
    "    # Calculate percentage of cells with more than current number of barcodes\n",
    "    percentage = np.sum(idx) / len(filtered_df[\"n_called_barcodes\"] >= 0)\n",
    "    percentage_more_than = np.append(percentage_more_than, percentage)\n",
    "\n",
    "# Save error rate data\n",
    "error_rate_df = pd.DataFrame({\n",
    "    \"num bc\": x,\n",
    "    \"error_rate\": error_rate_num_bc\n",
    "})\n",
    "error_rate_df.to_csv(os.path.join(data_output_folder, 'error_rate_equal_to_or_more.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
